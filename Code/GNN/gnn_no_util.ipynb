{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch_geometric.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"final_clean.csv\")\n",
    "\n",
    "df = df[['InvoiceNo', 'stockCodeTransform', 'CustomerID', 'Quantity']]\n",
    "\n",
    "df = df[df['Quantity'] > 0]\n",
    "\n",
    "customer_product_matrix = df.pivot_table(\n",
    "    index='CustomerID',\n",
    "    columns='stockCodeTransform',\n",
    "    values='Quantity',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "customer_product_matrix = (customer_product_matrix > 0).astype(int)\n",
    "\n",
    "train_ids, test_ids = train_test_split(customer_product_matrix.index, test_size=0.2, random_state=42)\n",
    "\n",
    "train_matrix = customer_product_matrix.loc[train_ids]\n",
    "test_matrix = customer_product_matrix.loc[test_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = customer_product_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_graph_from_data(df):\n",
    "    # Tiền xử lý: Mã hóa các cột cần thiết\n",
    "    le_country = LabelEncoder()\n",
    "    le_stock = LabelEncoder()\n",
    "    df[\"Country\"] = le_country.fit_transform(df[\"Country\"])\n",
    "    df[\"StockCode\"] = le_stock.fit_transform(df[\"StockCode\"])\n",
    "\n",
    "    # Chuẩn hóa các cột liên quan đến sản phẩm\n",
    "    scaler = MinMaxScaler()\n",
    "    df[[\"UnitPrice\", \"Utility\", \"rate\"]] = scaler.fit_transform(df[[\"UnitPrice\", \"Utility\", \"rate\"]])\n",
    "\n",
    "    # Tạo các đặc trưng cho khách hàng (Customer Features)\n",
    "    customer_features = df.groupby(\"CustomerID\").agg(\n",
    "        {\"Country\": \"mean\", \"rate\": \"mean\"}\n",
    "    ).reset_index()\n",
    "    customer_features_tensor = torch.tensor(customer_features.iloc[:, 1:].values, dtype=torch.float)\n",
    "\n",
    "    # Tạo các đặc trưng cho sản phẩm (Product Features)\n",
    "    product_features = df.groupby(\"StockCode\").agg(\n",
    "        {\"UnitPrice\": \"mean\", \"Utility\": \"mean\"}\n",
    "    ).reset_index()\n",
    "    product_features_tensor = torch.tensor(product_features.iloc[:, 1:].values, dtype=torch.float)\n",
    "\n",
    "    # Tạo danh sách tất cả các kết hợp (CustomerID, StockCode)\n",
    "    customers = df['CustomerID'].unique()\n",
    "    products = df['stockCodeTransform'].unique()\n",
    "\n",
    "    # Tạo một dictionary để xác định xem khách hàng có mua sản phẩm này không\n",
    "    purchase_dict = {(row['CustomerID'], row['stockCodeTransform']): 1 for _, row in df.iterrows()}\n",
    "\n",
    "    # Tạo đặc trưng cho các kết hợp (CustomerID, StockCode)\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "\n",
    "    # Lặp qua tất cả các khách hàng và sản phẩm để xây dựng đặc trưng cho mỗi cặp\n",
    "    for customer in tqdm(customers, desc=\"Processing customers\"):\n",
    "        for product in products:\n",
    "            # Lấy đặc trưng của khách hàng và sản phẩm\n",
    "            customer_feature = customer_features_tensor[customer_features[\"CustomerID\"] == customer][0]\n",
    "            product_feature = product_features_tensor[product_features[\"StockCode\"] == product][0]\n",
    "\n",
    "            # Ghép đặc trưng của khách hàng và sản phẩm thành một vector\n",
    "            combined_feature = list(customer_feature) + list(product_feature)\n",
    "            x1.append(combined_feature)\n",
    "\n",
    "            # Gán nhãn: Nếu cặp (customer, product) có trong purchase_dict thì gán nhãn = 1, ngược lại = 0\n",
    "            label = purchase_dict.get((customer, product), 0)\n",
    "            y1.append(label)\n",
    "\n",
    "    # Chuyển x và y thành tensor của PyTorch\n",
    "    x1_tensor = torch.tensor(np.array(x1), dtype=torch.float)\n",
    "    y_tensor = torch.tensor(np.array(y1), dtype=torch.long)\n",
    "\n",
    "    # Dữ liệu mô phỏng về danh sách khách hàng và sản phẩm để tạo nhãn\n",
    "    customers = df['CustomerID'].unique()\n",
    "    products = df['stockCodeTransform'].unique()\n",
    "\n",
    "    # Tạo danh sách tất cả các kết hợp (CustomerID, StockCode)\n",
    "    customer_product_combinations = [(customer, product) for customer in customers for product in products]\n",
    "    # Tạo danh sách các cạnh và trọng số\n",
    "    edges = []\n",
    "    edge_attr = []  # Trọng số cho các cạnh\n",
    "    customer_nodes = len(customers)  # Số lượng customer nodes\n",
    "    # Duyệt qua các kết hợp (CustomerID, StockCode)\n",
    "    for i, combination in enumerate(customer_product_combinations):\n",
    "        customer_id, stock_code = combination\n",
    "        # Nếu khách hàng đã mua sản phẩm này, trọng số = 1, nếu không, trọng số = 0\n",
    "        weight = 1 if (customer_id, stock_code) in purchase_dict else 0\n",
    "        edges.append((customer_id, stock_code))\n",
    "        edge_attr.append(weight)\n",
    "\n",
    "    # Chuyển edges thành tensor và edge_attr thành tensor\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Tạo Data cho đồ thị (graph)\n",
    "    graph = Data(x=x1_tensor, edge_index=edge_index, edge_attr=edge_attr, y=y_tensor)\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Ví dụ sử dụng hàm\n",
    "df = pd.read_csv(\"final_clean.csv\")\n",
    "graph = create_graph_from_data(df)\n",
    "\n",
    "# Kiểm tra cấu trúc dữ liệu\n",
    "print(\"Graph:\")\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "graph_train = create_graph_from_data(df_train)\n",
    "graph_test = create_graph_from_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[12563443, 4], edge_index=[2, 12564131], edge_attr=[12564131], y=[12563443])\n"
     ]
    }
   ],
   "source": [
    "print(graph_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3140861, 4], edge_index=[2, 3141032], edge_attr=[3141032], y=[3140861])\n"
     ]
    }
   ],
   "source": [
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GATModel, self).__init__()\n",
    "        # Giảm số lượng đầu vào (heads) và lớp ẩn\n",
    "        self.gat1 = GATConv(num_features, hidden_channels, heads=8, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * 8, num_classes, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = F.elu(self.gat1(x, edge_index, edge_attr))\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = graph_train.x.size(1)\n",
    "hidden_channels = 64\n",
    "num_classes = 2\n",
    "model = GATModel(num_features, hidden_channels, num_classes)\n",
    "\n",
    "class_weights = torch.tensor([1.0, 10])\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model at epoch 1 with loss: 0.6207, accuracy: 68.27%\n",
      "Epoch 1/300, Loss: 0.6207, Accuracy: 68.27%\n",
      "Saved best model at epoch 3 with loss: 0.5883, accuracy: 69.64%\n",
      "Saved best model at epoch 4 with loss: 0.5856, accuracy: 70.40%\n",
      "Saved best model at epoch 6 with loss: 0.5727, accuracy: 67.93%\n",
      "Saved best model at epoch 8 with loss: 0.5665, accuracy: 69.20%\n",
      "Saved best model at epoch 10 with loss: 0.5594, accuracy: 67.45%\n",
      "Saved best model at epoch 11 with loss: 0.5346, accuracy: 68.90%\n",
      "Epoch 11/300, Loss: 0.5346, Accuracy: 68.90%\n",
      "Saved best model at epoch 13 with loss: 0.5333, accuracy: 69.43%\n",
      "Saved best model at epoch 14 with loss: 0.5251, accuracy: 68.71%\n",
      "Saved best model at epoch 20 with loss: 0.4923, accuracy: 68.61%\n",
      "Epoch 21/300, Loss: 0.5141, Accuracy: 68.35%\n",
      "Saved best model at epoch 24 with loss: 0.4918, accuracy: 70.62%\n",
      "Saved best model at epoch 25 with loss: 0.4892, accuracy: 70.34%\n",
      "Saved best model at epoch 29 with loss: 0.4721, accuracy: 71.94%\n",
      "Epoch 31/300, Loss: 0.4888, Accuracy: 70.36%\n",
      "Saved best model at epoch 35 with loss: 0.4681, accuracy: 70.00%\n",
      "Epoch 41/300, Loss: 0.4906, Accuracy: 68.65%\n",
      "Saved best model at epoch 44 with loss: 0.4641, accuracy: 73.52%\n",
      "Epoch 51/300, Loss: 0.4801, Accuracy: 69.47%\n",
      "Saved best model at epoch 55 with loss: 0.4638, accuracy: 71.20%\n",
      "Saved best model at epoch 56 with loss: 0.4606, accuracy: 69.91%\n",
      "Saved best model at epoch 60 with loss: 0.4597, accuracy: 69.44%\n",
      "Epoch 61/300, Loss: 0.4770, Accuracy: 69.19%\n",
      "Saved best model at epoch 63 with loss: 0.4552, accuracy: 71.19%\n",
      "Epoch 71/300, Loss: 0.4717, Accuracy: 69.00%\n",
      "Epoch 81/300, Loss: 0.4596, Accuracy: 70.77%\n",
      "Saved best model at epoch 83 with loss: 0.4424, accuracy: 71.23%\n",
      "Epoch 91/300, Loss: 0.4639, Accuracy: 69.05%\n",
      "Saved best model at epoch 100 with loss: 0.4418, accuracy: 71.02%\n",
      "Epoch 101/300, Loss: 0.4607, Accuracy: 69.41%\n",
      "Epoch 111/300, Loss: 0.4458, Accuracy: 71.51%\n",
      "Epoch 121/300, Loss: 0.4664, Accuracy: 69.96%\n",
      "Early stopping at epoch 130/300 due to no improvement.\n",
      "Best model has loss: 0.4418 and accuracy: 71.02%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Huấn luyện mô hình với Early Stopping\n",
    "epochs = 300\n",
    "patience = 30  # Số epoch không cải thiện loss trước khi dừng lại\n",
    "best_loss = float('inf')  # Khởi tạo loss tốt nhất là vô cùng lớn\n",
    "best_accuracy = 0  # Khởi tạo accuracy tốt nhất là 0\n",
    "epochs_without_improvement = 0  # Đếm số epoch không cải thiện loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Đặt mô hình ở chế độ train\n",
    "    optimizer.zero_grad()  # Làm mới gradient\n",
    "    \n",
    "    # Tính toán đầu ra của mô hình\n",
    "    out = model(graph_train.x, graph_train.edge_index)  \n",
    "    \n",
    "    # Tính toán loss\n",
    "    loss = criterion(out, graph_train.y)  \n",
    "    \n",
    "    # Lan truyền gradient và cập nhật tham số của mô hình\n",
    "    loss.backward()  \n",
    "    optimizer.step()  \n",
    "    \n",
    "    # Tính toán accuracy\n",
    "    _, predicted = torch.max(out, 1)  # Lấy chỉ số của lớp dự đoán có xác suất cao nhất\n",
    "    correct = (predicted == graph_train.y).sum().item()  # Tính số lượng dự đoán đúng\n",
    "    accuracy = correct / graph_train.y.size(0)  # Tính accuracy\n",
    "    \n",
    "    # Kiểm tra xem loss có cải thiện hay không\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()  # Cập nhật loss tốt nhất\n",
    "        best_accuracy = accuracy  # Cập nhật accuracy tốt nhất\n",
    "        epochs_without_improvement = 0  # Reset số epoch không cải thiện\n",
    "        # Lưu mô hình tốt nhất và đè lên tệp hiện tại\n",
    "        torch.save(model.state_dict(), \"best_model_no_scale_1_64.pth\")\n",
    "        print(f\"Saved best model at epoch {epoch+1} with loss: {loss:.4f}, accuracy: {accuracy * 100:.2f}%\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1  # Tăng số epoch không cải thiện\n",
    "    \n",
    "    # In ra loss và accuracy mỗi 10 epoch\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Kiểm tra điều kiện Early Stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}/{epochs} due to no improvement.\")\n",
    "        break\n",
    "\n",
    "# In ra thông tin về mô hình tốt nhất\n",
    "print(f\"Best model has loss: {best_loss:.4f} and accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Loss: 0.5016\n",
      "Best Model Test Accuracy: 70.68%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Đặt mô hình ở chế độ đánh giá (evaluation)\n",
    "\n",
    "# Kiểm tra trên tập kiểm tra (test set)\n",
    "with torch.no_grad():  # Không tính gradient khi đánh giá\n",
    "    out_test = model(graph_test.x, graph_test.edge_index)  # Áp dụng mô hình lên tập test\n",
    "    \n",
    "    # Tính toán loss trên tập test\n",
    "    loss_test = criterion(out_test, graph_test.y)  # Tính loss (CrossEntropyLoss)\n",
    "    \n",
    "    # Tính toán accuracy trên tập test\n",
    "    _, predicted_test = torch.max(out_test, 1)  # Lấy chỉ số của lớp dự đoán có xác suất cao nhất\n",
    "    correct_test = (predicted_test == graph_test.y).sum().item()  # Tính số lượng dự đoán đúng\n",
    "    accuracy_test = correct_test / graph_test.y.size(0)  # Tính accuracy trên tập test\n",
    "\n",
    "    print(f\"Best Model Test Loss: {loss_test.item():.4f}\")\n",
    "    print(f\"Best Model Test Accuracy: {accuracy_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_recommendations(user_id, matrix, model, graph_data, probability_threshold=0.6, num_suggestions=10):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(graph_data.x, graph_data.edge_index)\n",
    "        product_probs = torch.softmax(predictions[len(matrix):], dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    purchased_products = matrix.loc[user_id][matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    predicted_products = [\n",
    "        col for col, prob in zip(matrix.columns, product_probs)\n",
    "        if prob > probability_threshold and col not in purchased_products\n",
    "    ]\n",
    "\n",
    "    predicted_products_sorted = sorted(predicted_products, key=lambda x: product_probs[matrix.columns.get_loc(x)], reverse=True)\n",
    "\n",
    "    recommended_products = predicted_products_sorted[:num_suggestions]\n",
    "\n",
    "    return recommended_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gợi ý sản phẩm cho User 15463 : [(23565, 0.99515355), (23481, 0.99657357), (72128, 0.998004), (22102, 0.99658453), (20914, 0.99612033), (23527, 0.9939475), (9021418, 0.9969183), (22824, 0.9950186), (84754, 0.99550396), (21158, 0.9973979)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test hàm\n",
    "user_id = 15463  # Giả sử bạn muốn gợi ý cho User 0\n",
    "recommended_products = get_product_recommendations(user_id, test_matrix, model, graph_test)\n",
    "\n",
    "print(\"Gợi ý sản phẩm cho User\", user_id, \":\", recommended_products)\n",
    "len(recommended_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend products customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 4312/4312 [45:58<00:00,  1.56user/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gợi ý sản phẩm cho các user đã được lưu vào file 'user_product_recommendations_gnn_util.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "user_ids = data_matrix.index.tolist()\n",
    "\n",
    "all_recommendations = []\n",
    "\n",
    "for user_id in tqdm(user_ids, desc=\"Processing Users\", unit=\"user\"):\n",
    "    recommended_products = get_product_recommendations(user_id, data_matrix, model, data, product_weights)\n",
    "    all_recommendations.append({'user_id': user_id, 'recommended_products': recommended_products})\n",
    "\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "\n",
    "recommendations_df.to_csv('user_product_recommendations_gnn_no_util.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lợi nhuận trung bình tất cả user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 4312/4312 [00:18<00:00, 235.07user/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị trung bình của tất cả user: 22.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "recommendations_df = pd.read_csv('user_product_recommendations_gnn_no_util.csv')\n",
    "items_df = pd.read_csv('items.csv')\n",
    "\n",
    "items_df['stockCodeTransform'] = items_df['stockCodeTransform'].astype(str)\n",
    "\n",
    "user_values = []\n",
    "\n",
    "for user_id in tqdm(recommendations_df['user_id'], desc=\"Processing Users\", unit=\"user\"):\n",
    "    recommended_products = recommendations_df[recommendations_df['user_id'] == user_id]['recommended_products'].values[0]\n",
    "    \n",
    "    if pd.isna(recommended_products):\n",
    "        continue\n",
    "    \n",
    "    recommended_products = [str(product[0]) for product in eval(recommended_products)]\n",
    "    \n",
    "    total_value = 0\n",
    "    for product in recommended_products:\n",
    "        product = product.strip()\n",
    "        product_info = items_df[items_df['stockCodeTransform'] == product]\n",
    "        if not product_info.empty:\n",
    "            unit_price = product_info['UnitPrice'].values[0]\n",
    "            quantity = product_info['Quantity'].values[0]\n",
    "            product_value = unit_price * quantity\n",
    "            total_value += product_value\n",
    "    \n",
    "    if len(recommended_products) > 0:\n",
    "        avg_value = total_value / len(recommended_products)\n",
    "        user_values.append(avg_value)\n",
    "\n",
    "average_value = sum(user_values) / len(user_values) if user_values else 0\n",
    "\n",
    "print(f\"Giá trị trung bình của tất cả user: {average_value:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
