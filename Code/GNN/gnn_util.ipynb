{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch_geometric.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"final_clean.csv\")\n",
    "\n",
    "df = df[['InvoiceNo', 'stockCodeTransform', 'CustomerID', 'Quantity']]\n",
    "\n",
    "df = df[df['Quantity'] > 0]\n",
    "\n",
    "customer_product_matrix = df.pivot_table(\n",
    "    index='CustomerID',\n",
    "    columns='stockCodeTransform',\n",
    "    values='Quantity',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "customer_product_matrix = (customer_product_matrix > 0).astype(int)\n",
    "\n",
    "train_ids, test_ids = train_test_split(customer_product_matrix.index, test_size=0.2, random_state=42)\n",
    "\n",
    "train_matrix = customer_product_matrix.loc[train_ids]\n",
    "test_matrix = customer_product_matrix.loc[test_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix =  customer_product_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Hàm load dữ liệu từ file và trả về product_weights\n",
    "def load_product_pairs(filename):\n",
    "    product_weights = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if '#UTIL:' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split('  #UTIL:')\n",
    "            try:\n",
    "                products = list(map(int, parts[0].split()))\n",
    "                weight = int(parts[1])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "            for i in range(len(products)):\n",
    "                for j in range(i + 1, len(products)):\n",
    "                    p1, p2 = sorted([products[i], products[j]])\n",
    "                    if (p1, p2) not in product_weights:\n",
    "                        product_weights[(p1, p2)] = 0\n",
    "                    product_weights[(p1, p2)] += weight\n",
    "    return product_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu và tạo đồ thị\n",
    "product_weights = load_product_pairs('hui_eihi.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_graph_from_data(df):\n",
    "    # Tiền xử lý: Mã hóa các cột cần thiết\n",
    "    le_country = LabelEncoder()\n",
    "    le_stock = LabelEncoder()\n",
    "    df[\"Country\"] = le_country.fit_transform(df[\"Country\"])\n",
    "    df[\"StockCode\"] = le_stock.fit_transform(df[\"StockCode\"])\n",
    "\n",
    "    # Chuẩn hóa các cột liên quan đến sản phẩm\n",
    "    scaler = MinMaxScaler()\n",
    "    df[[\"UnitPrice\", \"Utility\", \"rate\"]] = scaler.fit_transform(df[[\"UnitPrice\", \"Utility\", \"rate\"]])\n",
    "\n",
    "    # Tạo các đặc trưng cho khách hàng (Customer Features)\n",
    "    customer_features = df.groupby(\"CustomerID\").agg(\n",
    "        {\"Country\": \"mean\", \"rate\": \"mean\"}\n",
    "    ).reset_index()\n",
    "    customer_features_tensor = torch.tensor(customer_features.iloc[:, 1:].values, dtype=torch.float)\n",
    "\n",
    "    # Tạo các đặc trưng cho sản phẩm (Product Features)\n",
    "    product_features = df.groupby(\"StockCode\").agg(\n",
    "        {\"UnitPrice\": \"mean\", \"Utility\": \"mean\"}\n",
    "    ).reset_index()\n",
    "    product_features_tensor = torch.tensor(product_features.iloc[:, 1:].values, dtype=torch.float)\n",
    "\n",
    "    # Tạo danh sách tất cả các kết hợp (CustomerID, StockCode)\n",
    "    customers = df['CustomerID'].unique()\n",
    "    products = df['stockCodeTransform'].unique()\n",
    "\n",
    "    # Tạo một dictionary để xác định xem khách hàng có mua sản phẩm này không\n",
    "    purchase_dict = {(row['CustomerID'], row['stockCodeTransform']): 1 for _, row in df.iterrows()}\n",
    "\n",
    "    # Tạo đặc trưng cho các kết hợp (CustomerID, StockCode)\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "\n",
    "    # Lặp qua tất cả các khách hàng và sản phẩm để xây dựng đặc trưng cho mỗi cặp\n",
    "    for customer in tqdm(customers, desc=\"Processing customers\"):\n",
    "        for product in products:\n",
    "            # Lấy đặc trưng của khách hàng và sản phẩm\n",
    "            customer_feature = customer_features_tensor[customer_features[\"CustomerID\"] == customer][0]\n",
    "            product_feature = product_features_tensor[product_features[\"StockCode\"] == product][0]\n",
    "\n",
    "            # Ghép đặc trưng của khách hàng và sản phẩm thành một vector\n",
    "            combined_feature = list(customer_feature) + list(product_feature)\n",
    "            x1.append(combined_feature)\n",
    "\n",
    "            # Gán nhãn: Nếu cặp (customer, product) có trong purchase_dict thì gán nhãn = 1, ngược lại = 0\n",
    "            label = purchase_dict.get((customer, product), 0)\n",
    "            y1.append(label)\n",
    "\n",
    "    # Chuyển x và y thành tensor của PyTorch\n",
    "    x1_tensor = torch.tensor(np.array(x1), dtype=torch.float)\n",
    "    y_tensor = torch.tensor(np.array(y1), dtype=torch.long)\n",
    "\n",
    "    # Dữ liệu mô phỏng về danh sách khách hàng và sản phẩm để tạo nhãn\n",
    "    customers = df['CustomerID'].unique()\n",
    "    products = df['stockCodeTransform'].unique()\n",
    "\n",
    "    # Tạo danh sách tất cả các kết hợp (CustomerID, StockCode)\n",
    "    customer_product_combinations = [(customer, product) for customer in customers for product in products]\n",
    "    # Tạo danh sách các cạnh và trọng số\n",
    "    edges = []\n",
    "    edge_attr = []  # Trọng số cho các cạnh\n",
    "    customer_nodes = len(customers)  # Số lượng customer nodes\n",
    "    # Duyệt qua các kết hợp (CustomerID, StockCode)\n",
    "    for i, combination in enumerate(customer_product_combinations):\n",
    "        customer_id, stock_code = combination\n",
    "        # Nếu khách hàng đã mua sản phẩm này, trọng số = 1, nếu không, trọng số = 0\n",
    "        weight = 1 if (customer_id, stock_code) in purchase_dict else 0\n",
    "        edges.append((customer_id, stock_code))\n",
    "        edge_attr.append(weight)\n",
    "\n",
    "    # Chuẩn hóa trọng số sản phẩm nếu có mối quan hệ giữa các sản phẩm\n",
    "    if product_weights:\n",
    "        # Tạo danh sách các trọng số trước khi chuẩn hóa\n",
    "        raw_weights = list(product_weights.values())\n",
    "\n",
    "        # Chuẩn hóa trọng số sản phẩm về khoảng [0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_weights = scaler.fit_transform(np.array(raw_weights).reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Tạo các cạnh giữa các sản phẩm và thêm trọng số\n",
    "        idx = 0\n",
    "        for (p1, p2), weight in product_weights.items():\n",
    "            if p1 in product_features[\"stockCodeTransform\"].values and p2 in product_features[\"stockCodeTransform\"].values:\n",
    "                # Lấy chỉ số của sản phẩm trong danh sách sản phẩm\n",
    "                p1_idx = list(product_features[\"stockCodeTransform\"]).index(p1)\n",
    "                p2_idx = list(product_features[\"stockCodeTransform\"]).index(p2)\n",
    "                \n",
    "                # Tạo các cạnh giữa các sản phẩm và thêm trọng số đã chuẩn hóa\n",
    "                edges.append([customer_nodes + p1_idx, customer_nodes + p2_idx])\n",
    "                edge_attr.append(scaled_weights[idx])  # Trọng số đã chuẩn hóa\n",
    "                edges.append([customer_nodes + p2_idx, customer_nodes + p1_idx])\n",
    "                edge_attr.append(scaled_weights[idx])  # Trọng số cho cạnh ngược lại\n",
    "                idx += 1\n",
    "    # Chuyển edges thành tensor và edge_attr thành tensor\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Tạo Data cho đồ thị (graph)\n",
    "    graph = Data(x=x1_tensor, edge_index=edge_index, edge_attr=edge_attr, y=y_tensor)\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Ví dụ sử dụng hàm\n",
    "df = pd.read_csv(\"final_clean.csv\")\n",
    "graph = create_graph_from_data(df)\n",
    "\n",
    "# Kiểm tra cấu trúc dữ liệu\n",
    "print(\"Graph:\")\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "graph_train = create_graph_from_data(df_train)\n",
    "graph_test = create_graph_from_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải lại đối tượng data từ file\n",
    "data = torch.load('graph_data.pt')\n",
    "\n",
    "# Kiểm tra nội dung của loaded_data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[12563443, 4], edge_index=[2, 12564131], edge_attr=[12564131], y=[12563443])\n"
     ]
    }
   ],
   "source": [
    "print(graph_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3140861, 4], edge_index=[2, 3141032], edge_attr=[3141032], y=[3140861])\n"
     ]
    }
   ],
   "source": [
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GATModel, self).__init__()\n",
    "        # Giảm số lượng đầu vào (heads) và lớp ẩn\n",
    "        self.gat1 = GATConv(num_features, hidden_channels, heads=8, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * 8, num_classes, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = F.elu(self.gat1(x, edge_index, edge_attr))\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = graph_train.x.size(1)\n",
    "hidden_channels = 64\n",
    "num_classes = 2\n",
    "model = GATModel(num_features, hidden_channels, num_classes)\n",
    "\n",
    "class_weights = torch.tensor([1.0, 10])\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model at epoch 1 with loss: 0.3858, accuracy: 85.25%\n",
      "Epoch 1/300, Loss: 0.3858, Accuracy: 85.25%\n",
      "Saved best model at epoch 2 with loss: 0.3593, accuracy: 87.20%\n",
      "Epoch 11/300, Loss: 0.3640, Accuracy: 86.42%\n",
      "Saved best model at epoch 18 with loss: 0.3576, accuracy: 87.98%\n",
      "Epoch 21/300, Loss: 0.3692, Accuracy: 84.92%\n",
      "Epoch 31/300, Loss: 0.3686, Accuracy: 85.53%\n",
      "Saved best model at epoch 33 with loss: 0.3257, accuracy: 88.03%\n",
      "Epoch 41/300, Loss: 0.3745, Accuracy: 84.56%\n",
      "Epoch 51/300, Loss: 0.3585, Accuracy: 86.57%\n",
      "Epoch 61/300, Loss: 0.3678, Accuracy: 85.07%\n",
      "Early stopping at epoch 63/300 due to no improvement.\n",
      "Best model has loss: 0.3257 and accuracy: 88.03%\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "patience = 30\n",
    "best_loss = float('inf')\n",
    "best_accuracy = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(graph_train.x, graph_train.edge_index)\n",
    "    loss = criterion(out, graph_train.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, predicted = torch.max(out, 1)\n",
    "    correct = (predicted == graph_train.y).sum().item()\n",
    "    accuracy = correct / graph_train.y.size(0)\n",
    "    \n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        best_accuracy = accuracy\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model_no_scale_1_64_best.pth\")\n",
    "        print(f\"Saved best model at epoch {epoch+1} with loss: {loss:.4f}, accuracy: {accuracy * 100:.2f}%\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}/{epochs} due to no improvement.\")\n",
    "        break\n",
    "\n",
    "print(f\"Best model has loss: {best_loss:.4f} and accuracy: {best_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Loss: 0.4091\n",
      "Best Model Test Accuracy: 81.33%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_test = model(graph_test.x, graph_test.edge_index)\n",
    "    loss_test = criterion(out_test, graph_test.y)\n",
    "    \n",
    "    _, predicted_test = torch.max(out_test, 1)\n",
    "    correct_test = (predicted_test == graph_test.y).sum().item()\n",
    "    accuracy_test = correct_test / graph_test.y.size(0)\n",
    "\n",
    "    print(f\"Best Model Test Loss: {loss_test.item():.4f}\")\n",
    "    print(f\"Best Model Test Accuracy: {accuracy_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_recommendations(user_id, matrix, model, graph_data, probability_threshold=0.6, num_suggestions=10):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(graph_data.x, graph_data.edge_index)\n",
    "        product_probs = torch.softmax(predictions[len(matrix):], dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    purchased_products = matrix.loc[user_id][matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    predicted_products = [\n",
    "        col for col, prob in zip(matrix.columns, product_probs)\n",
    "        if prob > probability_threshold and col not in purchased_products\n",
    "    ]\n",
    "\n",
    "    predicted_products_sorted = sorted(predicted_products, key=lambda x: product_probs[matrix.columns.get_loc(x)], reverse=True)\n",
    "\n",
    "    recommended_products = predicted_products_sorted[:num_suggestions]\n",
    "\n",
    "    return recommended_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn một user cụ thể trong tập test\n",
    "example_user_id = test_matrix.index[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gợi ý sản phẩm cho User 15463 : [(22191, 0.99999964), (22197, 0.99866426), (23203, 0.99999964), (21731, 0.9999877), (8513613, 0.9994215), (21617, 0.9995957), (20801, 1.0), (22916, 1.0), (22492, 1.0), (8480112, 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test hàm\n",
    "user_id = 15463  # Giả sử bạn muốn gợi ý cho User 0\n",
    "recommended_products = get_product_recommendations(user_id, test_matrix, model, graph_test, product_weights)\n",
    "\n",
    "print(\"Gợi ý sản phẩm cho User\", user_id, \":\", recommended_products)\n",
    "len(recommended_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend products customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "user_ids = data_matrix.index.tolist()\n",
    "\n",
    "all_recommendations = []\n",
    "\n",
    "for user_id in tqdm(user_ids, desc=\"Processing Users\", unit=\"user\"):\n",
    "    recommended_products = get_product_recommendations(user_id, data_matrix, model, data, product_weights)\n",
    "    all_recommendations.append({'user_id': user_id, 'recommended_products': recommended_products})\n",
    "\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "\n",
    "recommendations_df.to_csv('user_product_recommendations_gnn_util.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lợi nhuận trung bình tất cả user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 4312/4312 [00:28<00:00, 152.52user/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị trung bình của tất cả user: 26.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "recommendations_df = pd.read_csv('user_product_recommendations_gnn_util.csv')\n",
    "items_df = pd.read_csv('items.csv')\n",
    "\n",
    "items_df['stockCodeTransform'] = items_df['stockCodeTransform'].astype(str)\n",
    "\n",
    "user_values = []\n",
    "\n",
    "for user_id in tqdm(recommendations_df['user_id'], desc=\"Processing Users\", unit=\"user\"):\n",
    "    recommended_products = recommendations_df[recommendations_df['user_id'] == user_id]['recommended_products'].values[0]\n",
    "    \n",
    "    if pd.isna(recommended_products):\n",
    "        continue\n",
    "    \n",
    "    recommended_products = [str(product[0]) for product in eval(recommended_products)]\n",
    "    \n",
    "    total_value = 0\n",
    "    for product in recommended_products:\n",
    "        product = product.strip()\n",
    "        product_info = items_df[items_df['stockCodeTransform'] == product]\n",
    "        if not product_info.empty:\n",
    "            unit_price = product_info['UnitPrice'].values[0]\n",
    "            quantity = product_info['Quantity'].values[0]\n",
    "            product_value = unit_price * quantity\n",
    "            total_value += product_value\n",
    "    \n",
    "    if len(recommended_products) > 0:\n",
    "        avg_value = total_value / len(recommended_products)\n",
    "        user_values.append(avg_value)\n",
    "\n",
    "average_value = sum(user_values) / len(user_values) if user_values else 0\n",
    "\n",
    "print(f\"Giá trị trung bình của tất cả user: {average_value:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
